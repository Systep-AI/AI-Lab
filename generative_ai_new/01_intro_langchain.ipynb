{"cells":[{"cell_type":"markdown","source":["# Clase 1: Introducción a LangChain\n","\n","**LangChain** es un framework diseñado para crear aplicaciones que aprovechen las capacidades de los modelos de lenguaje grandes (*LLMs*, por sus siglas en inglés).  \n","\n","Su objetivo principal es facilitar la integración de LLMs en flujos de trabajo complejos, brindando componentes y abstracciones que permitan a los desarrolladores construir aplicaciones robustas y escalables. Estas aplicaciones pueden ir desde tareas de generación de texto, respuesta a preguntas y resúmenes, hasta chatbots y sistemas autónomos más avanzados.\n","\n","\n","\n","## Características Principales\n","\n","1. **Componentes Modulares**  \n","   - LangChain se compone de bloques intercambiables y reutilizables, como *cadenas (chains), prompts, herramientas (tools), memorias (memory)* y *agentes (agents)*.  \n","   - Esta modularidad permite construir soluciones específicas o flujos de trabajo complejos, combinando diferentes piezas según tus necesidades.\n","\n","2. **Integración con Fuentes de Datos**  \n","   - Se integra con documentos externos, bases de datos y APIs para enriquecer el contexto de las respuestas generadas por el LLM.  \n","   - Usa *Document Loaders* y *VectorStores* para procesar y buscar información de manera eficiente.\n","\n","3. **Marcos de Agentes**  \n","   - Ofrece herramientas para crear agentes que “razonan” y “actúan” de acuerdo a la retroalimentación o las metas establecidas.  \n","   - Estos agentes pueden encadenar tareas, recurrir a herramientas externas (como buscadores) y mantener el estado de la conversación.\n","\n","4. **Manejo de Memoria**  \n","   - Con la *Memory*, el contexto de la conversación se puede conservar a lo largo de varios turnos.  \n","   - Útil para chatbots y respuestas coherentes en flujos interactivos prolongados.\n","\n","5. **Ingeniería de Prompts**  \n","   - Facilita la creación y experimentación de *prompts*, pudiendo usar variables dinámicas y plantillas para personalizar instrucciones.  \n","   - Esencial para guiar al LLM hacia la generación de resultados más pertinentes.\n","\n","6. **Optimización y Evaluación de Cadenas**  \n","   - Proporciona estrategias y herramientas para evaluar la calidad de la salida de tus *cadenas* y ajustarlas iterativamente.  \n","   - Permite ajustar la “temperatura” y experimentar con distintos modelos para optimizar resultados.\n","\n","## Casos de Uso\n","\n","1. **Chatbots y Agentes Conversacionales**  \n","   - Creación de asistentes virtuales que ofrezcan respuestas coherentes y contextuales a lo largo de múltiples intercambios.\n","\n","2. **Sistemas de Respuesta a Preguntas**  \n","   - Integración de información desde bases de datos o documentos para contestar consultas de manera precisa.\n","\n","3. **Herramientas de Resumen**  \n","   - Capacidad de condensar documentos extensos en resúmenes, informes o puntos clave.\n","\n","4. **Generación de Contenido Creativo**  \n","   - Elaboración de historias, guiones, poemas, artículos, etc., aprovechando la habilidad de los LLM para producir lenguaje natural.\n","\n","5. **Agentes Autónomos**  \n","   - Desarrollo de agentes que pueden autogestionar tareas basadas en objetivos o instrucciones del usuario.\n","\n","6. **Clasificación y Extracción de Datos**  \n","   - Uso de LLMs para etiquetar, extraer entidades o categorizar textos en grandes volúmenes de documentos.\n","\n","## Recomendaciones Generales\n","\n","  \n","- **Estructura Modular**  \n","  Divide tu aplicación en componentes (cadenas, herramientas, memorias) que sean fáciles de probar y mantener.\n","  \n","- **Monitorización y Ajustes**  \n","  Registra la actividad de tus cadenas para comprender mejor cómo está “razonando” el modelo y así poder optimizar tus prompts.\n","  \n","- **Experimentación Iterativa**  \n","  Ajusta parámetros como la *temperatura* (que controla la creatividad) y prueba diferentes LLMs para encontrar la configuración que mejor funcione.\n","  \n","- **Documentación Oficial**  \n","  Explora la [Documentación de LangChain](https://python.langchain.com/) para conocer las funcionalidades más recientes, ejemplos prácticos y mejores prácticas.\n","\n"],"metadata":{"id":"Avhgr--Wx_p5"}},{"cell_type":"markdown","source":["## Ejemplo Práctico: Respondedor de Preguntas con LangChain\n","\n","En este ejemplo, veremos cómo utilizar **LangChain** para responder preguntas de forma sencilla:\n","\n","1. Cargar claves API desde `.env` con la biblioteca `dotenv`.\n","2. Definir un *prompt template* para estructurar la pregunta.\n","3. Configurar el modelo de lenguaje (*ChatOpenAI*).\n","4. Crear una cadena con el *prompt* y el modelo.\n","5. Invocar la cadena para obtener una respuesta y mostrarla en pantalla.\n"],"metadata":{"id":"nS77k435nhyR"}},{"cell_type":"code","source":["# 0. instalar paquetes necesarios\n","!pip install python-dotenv langchain_openai\n","\n","# Nota: Si usas \"langchain\" oficial, reemplaza \"langchain_openai\" por \"langchain.chat_models\" u otro import apropiado."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzvgokcAmuih","executionInfo":{"status":"ok","timestamp":1739908470206,"user_tz":180,"elapsed":12784,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}},"outputId":"32c8e80f-4515-4ec9-8a86-1f22d9ef1ddd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.35)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.3.8)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (4.12.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.10.6)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.35->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.35->langchain_openai) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-dotenv, tiktoken, langchain_openai\n","Successfully installed langchain_openai-0.3.6 python-dotenv-1.0.1 tiktoken-0.9.0\n"]}]},{"cell_type":"code","source":["# 1. Importar las bibliotecas necesarias\n","import os\n","\n","from langchain.chains import LLMChain\n","from langchain_openai import ChatOpenAI  # Ajusta el import según la versión que uses\n","from langchain.prompts import PromptTemplate"],"metadata":{"id":"TYIunmOFnxpf","executionInfo":{"status":"ok","timestamp":1739908827117,"user_tz":180,"elapsed":14,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 1.1. Proporcionar directamente las claves de API\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-\"  # Reemplaza con tu clave real\n","\n","# Si usas otros servicios, agrégalos así:\n","# os.environ[\"SERPAPI_API_KEY\"] = \"tu_clave_aqui\"\n","# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"tu_clave_aqui\"\n","# os.environ[\"PINECONE_API_KEY\"] = \"tu_clave_aqui\"\n","# os.environ[\"TYPESENSE_API_KEY\"] = \"tu_clave_aqui\"\n","\n","print(\"Claves de API configuradas correctamente.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTAhyB0aoIt8","executionInfo":{"status":"ok","timestamp":1739908828124,"user_tz":180,"elapsed":46,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}},"outputId":"73e8b3fb-f93a-4c79-cb2b-186b7de56c41"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Claves de API configuradas correctamente.\n"]}]},{"cell_type":"code","source":["# 2. Crear una template de prompt\n","template = \"\"\"\n","Eres un asistente de IA. Responde a la siguiente pregunta de manera concisa y precisa:\n","Pregunta: {pregunta}\n","\"\"\"\n","prompt = PromptTemplate(template=template, input_variables=[\"pregunta\"])"],"metadata":{"id":"zjSywBPYnsKN","executionInfo":{"status":"ok","timestamp":1739908840192,"user_tz":180,"elapsed":37,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 3. Inicializar un modelo de lenguaje (LLM)\n","# Ajusta los parámetros según tus necesidades.\n","llm = ChatOpenAI(model='gpt-4o-2024-11-20', temperature=0.0)"],"metadata":{"id":"X7dFTdGUoUj6","executionInfo":{"status":"ok","timestamp":1739908843824,"user_tz":180,"elapsed":471,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 4. Crear la cadena (LLMChain)\n","chain = LLMChain(llm=llm, prompt=prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Erm2j6-5oW6t","executionInfo":{"status":"ok","timestamp":1739908845863,"user_tz":180,"elapsed":15,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}},"outputId":"3e1d8846-171e-4999-b48a-ce2d49b8b1e5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-26aacea9c609>:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n","  chain = LLMChain(llm=llm, prompt=prompt)\n"]}]},{"cell_type":"code","source":["# 5. Función de ejemplo para invocar la cadena\n","def ejecutar_chain():\n","    pregunta = \"¿Qué es LangChain y para qué se usa?\"\n","    output = chain.invoke({\"pregunta\": pregunta})\n","    respuesta = output[\"text\"]\n","\n","    print(\"Pregunta: \", pregunta)\n","    print(\"Respuesta:\", respuesta)\n","\n","# Llamamos a la función para ver el resultado\n","if __name__ == \"__main__\":\n","    ejecutar_chain()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwr6cbCXoZEM","executionInfo":{"status":"ok","timestamp":1739908851986,"user_tz":180,"elapsed":2459,"user":{"displayName":"Camilo Gutierrez","userId":"18212724788807677958"}},"outputId":"496f0353-5e09-4e84-97be-42273c1ff293"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Pregunta:  ¿Qué es LangChain y para qué se usa?\n","Respuesta: LangChain es un marco de desarrollo diseñado para crear aplicaciones impulsadas por modelos de lenguaje, como chatbots, asistentes virtuales o sistemas de generación de texto. Permite integrar modelos de lenguaje con fuentes de datos externas, como bases de datos o APIs, y gestionar flujos de trabajo complejos mediante cadenas de llamadas a estos modelos. Es útil para construir aplicaciones avanzadas de procesamiento de lenguaje natural (NLP).\n"]}]},{"cell_type":"markdown","source":["## Próximos Pasos\n","\n","- **Memoria Conversacional**: Agrega *Memory* para mantener el hilo de la conversación a lo largo de múltiples interacciones.  \n","- **Herramientas Externas**: Integra herramientas (*tools*) para que el modelo pueda realizar búsquedas, cálculos o consultas a bases de datos.  \n","- **Agentes Avanzados**: Explora la creación de agentes que decidan de manera autónoma qué acción o herramienta usar según la consulta del usuario.  \n","- **Procesamiento de Documentos**: Carga e indexa PDFs o páginas web usando *Document Loaders* y *VectorStores*, permitiendo respuestas más ricas y contextuales.  \n","\n","¡Con esto concluye la introducción a **LangChain** y un ejemplo básico de implementación! Te animo a experimentar y explorar las múltiples opciones que ofrece este framework para aprovechar todo el potencial de los modelos de lenguaje grandes.\n"],"metadata":{"id":"-hrRqEcQot4E"}}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb","timestamp":1726083614122}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}