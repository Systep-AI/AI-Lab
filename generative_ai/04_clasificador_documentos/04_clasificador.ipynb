{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avhgr--Wx_p5"
   },
   "source": [
    "# **Clasificador**\n",
    "\n",
    "Este notebook muestra cómo generar un clasificador de cartas relacionadas con el sistema eléctrico chileno, utilizando **LangChain** y un modelo de lenguaje.  \n",
    "\n",
    "La clasificación se basa en un *prompt* detallado que evalúa si una carta trata sobre **mantenimiento mayor** o no, devolviendo un valor **True** o **False**, según las reglas definidas en `prompt_summarizer`.  \n",
    "\n",
    "Los archivos de entrada deben estar en formato `.txt` dentro del directorio `/content/input`, y los resultados se guardan en un archivo Excel llamado `clasificacion_cartas.xlsx`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEYzR9stI8xd"
   },
   "source": [
    "# 1. Instalación de dependencias y librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JU-UKUoQIbT1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDPk3vqWJCJa"
   },
   "source": [
    "# 2. Configuración de variables de entorno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cy-_1129HlaL"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80ffSgpzJSPn"
   },
   "source": [
    "# 3. Definición del prompt de resumen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5QbxTHqxHobk"
   },
   "outputs": [],
   "source": [
    "prompt_summarizer = \"\"\"Este es el texto de una carta:\n",
    "\n",
    "{doc}\n",
    "\n",
    "Indica si la carta se trata sobre un mantenimiento mayor (True o False).\n",
    "Responde únicamente con True o False.\n",
    "\"\"\"\n",
    "\n",
    "# Plantilla que inyecta el texto de la carta en {doc}\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_summarizer,\n",
    "    input_variables=[\"doc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEC4mAQuwcMY"
   },
   "source": [
    "Prueba diferentes LLMs para encontrar la configuración que mejor funcione. El siguiente link contiene los [modelos de OpenAI](https://platform.openai.com/docs/models) disponibles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1740061224494,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "KS3E63dDwfvM",
    "outputId": "66580fd1-94a5-43e1-dbc1-e484258ebffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/yxsktyp14tggnw0jn6d4fz140000gn/T/ipykernel_60583/1973162587.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo (puedes ajustar model y temperature)\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-2024-11-20',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Crear el chain combinando prompt y LLM\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWYnOXlHJZK9"
   },
   "source": [
    "# 4. Clase Categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HJUS5rpyHs2p"
   },
   "outputs": [],
   "source": [
    "class Categorizer:\n",
    "    def __init__(self, chain, input_dir=\"/content\"):\n",
    "        \"\"\"\n",
    "        Construye un objeto para clasificar cartas de un directorio dado.\n",
    "        chain: LLMChain para ejecutar la clasificación.\n",
    "        input_dir: ruta que contiene los .txt a clasificar.\n",
    "        \"\"\"\n",
    "        self.chain = chain\n",
    "        self.input_dir = input_dir\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "        Lee cada .txt del directorio de entrada, ejecuta la clasificación,\n",
    "        y guarda un archivo Excel con los resultados.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        for filename in os.listdir(self.input_dir):\n",
    "            if filename.endswith('.txt'):\n",
    "                # Lee el contenido del archivo\n",
    "                file_path = os.path.join(self.input_dir, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                # Invocamos el Chain con la variable \"doc\"\n",
    "                output = self.chain.invoke({\"doc\": text})\n",
    "                # Obtenemos la clasificación (True o False)\n",
    "                classification = output.get(\"text\", \"\").strip()\n",
    "\n",
    "                results.append({\n",
    "                    \"Documento\": filename,\n",
    "                    \"MantenimientoMayor\": classification\n",
    "                })\n",
    "\n",
    "        # Convertimos la lista de resultados a DataFrame\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        # Guardamos a un Excel\n",
    "        df.to_excel('clasificacion_cartas.xlsx', index=False)\n",
    "        print(\"Clasificación completada. Resultados:\\n\")\n",
    "        print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1kLae06JfNn"
   },
   "source": [
    "# 5. Ejemplo de uso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4524,
     "status": "ok",
     "timestamp": 1740061303744,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "NEotgSk0HxDp",
    "outputId": "d7d674c8-18d8-4adb-ecd7-caf544985a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación completada. Resultados:\n",
      "\n",
      "        Documento MantenimientoMayor\n",
      "0  DE00179-25.txt              False\n",
      "1  DE00065-25.txt              False\n",
      "2  DE00196-25.txt               True\n",
      "3  DE00278-25.txt               True\n",
      "4  DE00362-25.txt               True\n",
      "5  DE00358-25.txt              False\n",
      "6  DE00303-25.txt               True\n",
      "7  DE00239-25.txt              False\n",
      "8  DE07524-24.txt               True\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto Categorizer pasando nuestro chain y la ruta de .txt\n",
    "categorizer = Categorizer(chain=chain, input_dir=\"documentos_prueba_txt/\")\n",
    "\n",
    "# Ejecutamos la clasificación\n",
    "categorizer.execute()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb",
     "timestamp": 1726083614122
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv_ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
