{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avhgr--Wx_p5"
   },
   "source": [
    "# **Clasificador**\n",
    "\n",
    "Este notebook muestra cómo generar un clasificador de cartas relacionadas con el sistema eléctrico chileno, utilizando **LangChain** y un modelo de lenguaje.  \n",
    "\n",
    "La clasificación se basa en un *prompt* detallado que evalúa si una carta trata sobre **mantenimiento mayor** o no, devolviendo un valor **True** o **False**, según las reglas definidas en `prompt_summarizer`.  \n",
    "\n",
    "Los archivos de entrada deben estar en formato `.txt` dentro del directorio `/content/input`, y los resultados se guardan en un archivo Excel llamado `clasificacion_cartas.xlsx`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEYzR9stI8xd"
   },
   "source": [
    "# 1. Instalación de dependencias y librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8155,
     "status": "ok",
     "timestamp": 1740064347137,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "JU-UKUoQIbT1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDPk3vqWJCJa"
   },
   "source": [
    "# 2. Configuración de variables de entorno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1740064349991,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "Cy-_1129HlaL"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-8v5h42HTpAHWUI3YlAnj1vKiFU9RizaF9w6APcg0AU0Lw7Pa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tXWxxJo5OST"
   },
   "source": [
    "# 3. Definición del prompt del parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1740064351318,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "jQTtbYVU4-Ve",
    "outputId": "fe0dc147-2771-4ef5-dea3-7024b0dd821b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrucciones de parseo definidas.\n"
     ]
    }
   ],
   "source": [
    "parsing_instructions = '''\n",
    "The document contains structured text that includes headers, dates, names of individuals, institutions, and places, as well as numbered sections, lists, and tables. Many of these documents feature text that is highly deteriorated and requires careful interpretation, contextualization, and reconstruction. Non-essential elements, such as scratches, signatures, and diagonal annotations, must be omitted.\n",
    "To ensure the integrity of the extracted information, the text must be preserved in its literal form without summarizing, paraphrasing, or modifying its meaning. Treat each document as evidentiary material, prioritizing rigorous and faithful extraction practices.\n",
    "Recognize that most documents are typewritten, which introduces specific challenges such as ink smudges, duplicated letters, and words split across lines. Proactively correct these errors, ensuring clarity and precision in the recovered content.\n",
    "While processing, handle page breaks to maintain the narrative flow, and retain the original structure of tables and lists without flattening their format. Extract and clearly highlight key names, dates, and places. Quotes, dialogues, abbreviations, and codes must be preserved exactly as they appear. Non-textual elements should be omitted to focus solely on the written content.\n",
    "The output should adhere to Markdown formatting conventions but must not include code block tags such as markdown. Use bold formatting for headers, numbered or bulleted lists for structured sections, block quotes for quoted material, and Markdown-compatible tables for tabular data. Narrative text should be continuous, providing both factual information and detailed descriptions, while preserving the integrity and original context of the document. Additionally, prioritize correcting OCR-related errors caused by typewriter artifacts whenever possible.\n",
    "The response must be exclusively in the original language of the document, which is generally Spanish. No translation or language modification is allowed.\n",
    "'''\n",
    "\n",
    "print(\"Instrucciones de parseo definidas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80ffSgpzJSPn"
   },
   "source": [
    "# 3.1. Definición del prompt de resumen\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1740064354150,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "5QbxTHqxHobk"
   },
   "outputs": [],
   "source": [
    "prompt_summarizer = \"\"\"Este es el texto de una carta:\n",
    "\n",
    "{doc}\n",
    "\n",
    "Indica si la carta se trata sobre un mantenimiento mayor (True o False).\n",
    "Responde únicamente con True o False.\n",
    "\"\"\"\n",
    "\n",
    "# Plantilla que inyecta el texto de la carta en {doc}\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_summarizer,\n",
    "    input_variables=[\"doc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEC4mAQuwcMY"
   },
   "source": [
    "Prueba diferentes LLMs para encontrar la configuración que mejor funcione. El siguiente link contiene los [modelos de OpenAI](https://platform.openai.com/docs/models) disponibles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1740064361390,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "KS3E63dDwfvM",
    "outputId": "f726bf92-5c45-4092-9e72-d596242abd95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/yxsktyp14tggnw0jn6d4fz140000gn/T/ipykernel_60918/1973162587.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo (puedes ajustar model y temperature)\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-2024-11-20',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Crear el chain combinando prompt y LLM\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWYnOXlHJZK9"
   },
   "source": [
    "# 4. Clase PDFtoTextConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1740064366326,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "jq30YRGW4XEe"
   },
   "outputs": [],
   "source": [
    "# Asegura que asyncio funcione correctamente en Colab/Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class PDFtoTextConverter:\n",
    "    \"\"\"\n",
    "    Clase encargada de convertir archivos PDF en texto plano (.txt) mediante LlamaParse.\n",
    "    \"\"\"\n",
    "    def __init__(self, parsing_instructions=None, language='es'):\n",
    "        \"\"\"\n",
    "        parsing_instructions: Reglas personalizadas para el parsing (ver docs de LlamaParse).\n",
    "        language: Idioma principal de extracción (ej. 'es').\n",
    "        \"\"\"\n",
    "        self.parsing_instructions = parsing_instructions\n",
    "        self.language = language\n",
    "\n",
    "    def convert_pdf_to_txt(self, pdf_path):\n",
    "        \"\"\"\n",
    "        Convierte un archivo PDF a .txt usando LlamaParse y devuelve la ruta\n",
    "        al archivo de texto resultante.\n",
    "        \"\"\"\n",
    "        parser = LlamaParse(\n",
    "            result_type=\"markdown\",\n",
    "            parsing_instructions=self.parsing_instructions,\n",
    "            language=self.language,\n",
    "            skip_diagonal_text=True,\n",
    "            do_not_unroll_columns=False\n",
    "        )\n",
    "\n",
    "        # Procesa y extrae el texto del PDF\n",
    "        document = parser.load_data(pdf_path)\n",
    "        full_text = ''\n",
    "        for section in document:\n",
    "            full_text += '\\n\\n' + section.text\n",
    "\n",
    "        # Crea el nombre de archivo .txt y lo escribe\n",
    "        txt_path = os.path.splitext(pdf_path)[0] + \".txt\"\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(full_text)\n",
    "\n",
    "        return txt_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgmXExXw59Uc"
   },
   "source": [
    "# 4.1. Clase Categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740064371126,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "HJUS5rpyHs2p"
   },
   "outputs": [],
   "source": [
    "class Categorizer:\n",
    "    \"\"\"\n",
    "    Clase encargada de:\n",
    "      1) Convertir PDFs a .txt (si no existen) usando la clase PDFtoTextConverter.\n",
    "      2) Leer los .txt y clasificarlos usando un LLMChain.\n",
    "    \"\"\"\n",
    "    def __init__(self, chain, ocr_converter=None, input_dir=\"/content\"):\n",
    "        \"\"\"\n",
    "        chain: LLMChain para ejecutar la clasificación.\n",
    "        ocr_converter: Instancia de PDFtoTextConverter para convertir PDFs a .txt.\n",
    "        input_dir: ruta que contiene los .pdf y/o .txt a clasificar.\n",
    "        \"\"\"\n",
    "        self.chain = chain\n",
    "        self.ocr_converter = ocr_converter  # Puede ser None si no se desea conversión\n",
    "        self.input_dir = input_dir\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "        1) Convierte cada .pdf del directorio a .txt (si no existen).\n",
    "        2) Lee cada .txt del directorio, ejecuta la clasificación,\n",
    "        3) Guarda un archivo Excel con los resultados.\n",
    "        \"\"\"\n",
    "        # 1) Si hay PDF, conviértelos a .txt\n",
    "        if self.ocr_converter:\n",
    "            for filename in os.listdir(self.input_dir):\n",
    "                if filename.lower().endswith('.pdf'):\n",
    "                    pdf_path = os.path.join(self.input_dir, filename)\n",
    "                    self.ocr_converter.convert_pdf_to_txt(pdf_path)\n",
    "\n",
    "        # 2) Clasificar cada archivo .txt existente en el directorio\n",
    "        results = []\n",
    "        for filename in os.listdir(self.input_dir):\n",
    "            if filename.lower().endswith('.txt'):\n",
    "                file_path = os.path.join(self.input_dir, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                # Llama a la cadena (Chain) con la variable \"doc\"\n",
    "                output = self.chain.invoke({\"doc\": text})\n",
    "                # Asume que el Chain retorna algo en \"text\" (True/False u otra etiqueta)\n",
    "                classification = output.get(\"text\", \"\").strip()\n",
    "\n",
    "                results.append({\n",
    "                    \"Documento\": filename,\n",
    "                    \"MantenimientoMayor\": classification\n",
    "                })\n",
    "\n",
    "        # 3) Exportar a Excel\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_excel('clasificacion_cartas.xlsx', index=False)\n",
    "        print(\"Clasificación completada. Resultados:\\n\")\n",
    "        print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1kLae06JfNn"
   },
   "source": [
    "# 5. Ejemplo de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPLJb1ZP6HpX"
   },
   "source": [
    "Importar directorio con documentos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 71469,
     "status": "error",
     "timestamp": 1740064604863,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "NEotgSk0HxDp",
    "outputId": "8df163c8-adda-4163-9db7-58a4fa7ef69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 15a7874e-a9c6-4564-a19c-a8cfa15d42c8\n",
      ".Started parsing the file under job_id 7acd1eca-1cd9-4376-9285-931c355ed4f0\n",
      "Started parsing the file under job_id 9ceea4a8-5fce-444a-ba1b-018c6ecfa73f\n",
      "Started parsing the file under job_id 361780a6-2998-458f-9160-fcec23c04b8f\n",
      "Started parsing the file under job_id 1e4a8712-88e4-4298-ba02-2d1cbccf1f0b\n",
      "Started parsing the file under job_id c71c37d7-6963-4386-b519-6487295b3b08\n",
      "Started parsing the file under job_id eb693998-c97b-41da-8952-b5e9b6b1524a\n",
      "Started parsing the file under job_id c8268dd8-c6b1-4a64-a080-4ca908d64330\n",
      "Started parsing the file under job_id 09b39916-241f-470a-b565-e78036168201\n",
      "Clasificación completada. Resultados:\n",
      "\n",
      "        Documento MantenimientoMayor\n",
      "0  DE00179-25.txt              False\n",
      "1  DE00065-25.txt              False\n",
      "2  DE00196-25.txt               True\n",
      "3  DE00278-25.txt               True\n",
      "4  DE00362-25.txt               True\n",
      "5  DE00358-25.txt              False\n",
      "6  DE00303-25.txt               True\n",
      "7  DE00239-25.txt              False\n",
      "8  DE07524-24.txt               True\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos OCR\n",
    "ocr = PDFtoTextConverter(parsing_instructions=parsing_instructions, language='es')\n",
    "# Creamos un objeto Categorizer pasando nuestro chain y la ruta de .txt\n",
    "categorizer = Categorizer(chain=chain, ocr_converter=ocr, input_dir=\"documentos_prueba/\")\n",
    "# Ejecutamos la clasificación\n",
    "categorizer.execute()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb",
     "timestamp": 1726083614122
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv_ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
