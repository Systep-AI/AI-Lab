{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avhgr--Wx_p5"
   },
   "source": [
    "# Clase 1: Introducción a LangChain\n",
    "\n",
    "**LangChain** es un framework diseñado para crear aplicaciones que aprovechen las capacidades de los modelos de lenguaje grandes (*LLMs*, por sus siglas en inglés).  \n",
    "\n",
    "Su objetivo principal es facilitar la integración de LLMs en flujos de trabajo complejos, brindando componentes y abstracciones que permitan a los desarrolladores construir aplicaciones robustas y escalables. Estas aplicaciones pueden ir desde tareas de generación de texto, respuesta a preguntas y resúmenes, hasta chatbots y sistemas autónomos más avanzados.\n",
    "\n",
    "\n",
    "\n",
    "## Características Principales\n",
    "\n",
    "1. **Componentes Modulares**  \n",
    "   - LangChain se compone de bloques intercambiables y reutilizables, como *cadenas (chains), prompts, herramientas (tools), memorias (memory)* y *agentes (agents)*.  \n",
    "   - Esta modularidad permite construir soluciones específicas o flujos de trabajo complejos, combinando diferentes piezas según tus necesidades.\n",
    "\n",
    "2. **Integración con Fuentes de Datos**  \n",
    "   - Se integra con documentos externos, bases de datos y APIs para enriquecer el contexto de las respuestas generadas por el LLM.  \n",
    "\n",
    "3. **Marcos de Agentes**  \n",
    "   - Ofrece herramientas para crear agentes que “razonan” y “actúan” de acuerdo a la retroalimentación o las metas establecidas.  \n",
    "\n",
    "4. **Ingeniería de Prompts**  \n",
    "   - Facilita la creación y experimentación de *prompts*, pudiendo usar variables dinámicas y plantillas para personalizar instrucciones.  \n",
    "   - Esencial para guiar al LLM hacia la generación de resultados más pertinentes.\n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "1. **Chatbots y Agentes Conversacionales**  \n",
    "   - Creación de asistentes virtuales que ofrezcan respuestas coherentes y contextuales a lo largo de múltiples intercambios.\n",
    "\n",
    "2. **Sistemas de Respuesta a Preguntas**  \n",
    "   - Integración de información desde bases de datos o documentos para contestar consultas de manera precisa.\n",
    "\n",
    "3. **Herramientas de Resumen**  \n",
    "   - Capacidad de condensar documentos extensos en resúmenes, informes o puntos clave.\n",
    "\n",
    "4. **Clasificación y Extracción de Datos**  \n",
    "   - Uso de LLMs para etiquetar, extraer entidades o categorizar textos en grandes volúmenes de documentos.\n",
    "\n",
    "## Recomendaciones Generales\n",
    "\n",
    "  \n",
    "- **Estructura Modular**  \n",
    "  Divide tu aplicación en componentes (cadenas, herramientas, memorias) que sean fáciles de probar y mantener.\n",
    "  \n",
    "- **Experimentación Iterativa**  \n",
    "  Prueba diferentes LLMs para encontrar la configuración que mejor funcione. El siguiente link contiene los [modelos de OpenAI](https://platform.openai.com/docs/models) disponibles.\n",
    "  \n",
    "- **Documentación Oficial**  \n",
    "  Explora la [Documentación de LangChain](https://python.langchain.com/) para conocer las funcionalidades más recientes, ejemplos prácticos y mejores prácticas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS77k435nhyR"
   },
   "source": [
    "## Ejemplo Práctico: Respondedor de Preguntas con LangChain\n",
    "\n",
    "En este ejemplo, veremos cómo utilizar **LangChain** para responder preguntas de forma sencilla:\n",
    "\n",
    "1. Cargar `API-KEY`.\n",
    "2. Definir un *prompt template* para estructurar la pregunta.\n",
    "3. Configurar el modelo de lenguaje (*ChatOpenAI*).\n",
    "4. Crear una cadena con el *prompt* y el modelo.\n",
    "5. Invocar la cadena para obtener una respuesta y mostrarla en pantalla.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DSBrUXJ17l_"
   },
   "source": [
    "# 1. Importar las bibliotecas necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5544,
     "status": "ok",
     "timestamp": 1740059077529,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "TYIunmOFnxpf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5oxrurU1-BE"
   },
   "source": [
    "# 1.1. Proporcionar directamente las claves de API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740059081131,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "CTAhyB0aoIt8",
    "outputId": "4a1f331d-07b2-4c04-d876-116cfc4f6d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves de API configuradas correctamente.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "print(\"Claves de API configuradas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkMqIzkN2Ai2"
   },
   "source": [
    "# 2. Crear una template de prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740059088395,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "zjSywBPYnsKN"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Eres un asistente de IA. Responde a la siguiente pregunta de manera concisa y precisa:\n",
    "Pregunta: {pregunta}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"pregunta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIvWFteO2CT0"
   },
   "source": [
    "# 3. Inicializar un modelo de lenguaje (LLM)\n",
    "\n",
    "Prueba diferentes LLMs para encontrar la configuración que mejor funcione. El siguiente link contiene los [modelos de OpenAI](https://platform.openai.com/docs/models) disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1740059090164,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "X7dFTdGUoUj6"
   },
   "outputs": [],
   "source": [
    "# Ajusta los parámetros según tus necesidades.\n",
    "llm = ChatOpenAI(model='gpt-4o-2024-11-20', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q5-IdIB2ER3"
   },
   "source": [
    "# 4. Crear la cadena (LLMChain)\n",
    "\n",
    "La siguiente instrucción crea una cadena en `LangChain` que toma un `prompt`y lo conecta a un modelo de lenguaje (`llm`), permitiendo generar respuestas automatizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740059091490,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "Erm2j6-5oW6t",
    "outputId": "57b411d2-b4a8-4ed6-fe17-df1879bd0e91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/yxsktyp14tggnw0jn6d4fz140000gn/T/ipykernel_59413/1305865249.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFNxLKrg2GQn"
   },
   "source": [
    "# 5. Función de ejemplo para invocar la cadena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2352,
     "status": "ok",
     "timestamp": 1740059095081,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "lwr6cbCXoZEM",
    "outputId": "afd11985-2921-484e-8c3d-83a038692d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: \n",
      " ¿Qué es LangChain y para qué se usa?\n",
      "Respuesta: \n",
      " LangChain es un marco de desarrollo diseñado para crear aplicaciones impulsadas por modelos de lenguaje, como chatbots, asistentes virtuales o sistemas de generación de texto. Permite integrar modelos de lenguaje con fuentes de datos externas (APIs, bases de datos, etc.) y gestionar flujos de trabajo complejos mediante cadenas de llamadas a estos modelos. Es útil para construir aplicaciones avanzadas de IA que requieran interacción dinámica y procesamiento de datos.\n"
     ]
    }
   ],
   "source": [
    "def ejecutar_chain():\n",
    "    pregunta = \"¿Qué es LangChain y para qué se usa?\"\n",
    "    output = chain.invoke({\"pregunta\": pregunta})\n",
    "    respuesta = output[\"text\"]\n",
    "\n",
    "    print(\"Pregunta: \\n\", pregunta)\n",
    "    print(\"Respuesta: \\n\", respuesta)\n",
    "\n",
    "# Llamamos a la función para ver el resultado\n",
    "if __name__ == \"__main__\":\n",
    "    ejecutar_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hrRqEcQot4E"
   },
   "source": [
    "\n",
    "\n",
    "¡Con esto concluye la introducción a **LangChain** y un ejemplo básico de implementación! Te animo a experimentar y explorar las múltiples opciones que ofrece este framework para aprovechar todo el potencial de los modelos de lenguaje grandes.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb",
     "timestamp": 1726083614122
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv_ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
