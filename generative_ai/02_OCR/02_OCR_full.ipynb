{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkC6T4zE6GHK"
   },
   "source": [
    "# **OCR**\n",
    "\n",
    "En este notebook veremos cómo **convertir diversos formatos de archivo a PDF** (por ejemplo, TIFF, ZIP con múltiples archivos, documentos de LibreOffice, etc.) y luego **parsearlos con [LlamaParse](https://pypi.org/project/llama-parse/)** para extraer texto de forma estructurada y confiable.  \n",
    "\n",
    "El flujo principal será:\n",
    "\n",
    "1. **Instalación de dependencias.**  \n",
    "2. **Definición de la librería de funciones para conversión a PDF.**  \n",
    "3. **Configuración previa (variables de entorno, etc.).**  \n",
    "4. **Definir la ruta del documento PDF final.**  \n",
    "5. **Establecer instrucciones de parseo (OCR y formato).**  \n",
    "6. **Procesar el PDF con LlamaParse.**  \n",
    "7. **Almacenar el texto resultante en un archivo local.**  \n",
    "8. **Visualizar una sección del documento parseado.**  \n",
    "\n",
    "\n",
    "\n",
    "## **Notas**\n",
    "- Si necesitas extraer texto de un archivo que NO sea PDF, primero utiliza la **librería de conversión** (en la Celda 2) para transformarlo en un PDF válido.\n",
    "- Configura la variable de entorno `LLAMA_CLOUD_API_KEY` con tu clave real para poder usar **LlamaParse**.\n",
    "- Ajusta los parámetros de `LlamaParse` (por ejemplo, `premium_mode`, `language`, etc.) en función de tus necesidades de OCR y parseo.\n",
    "- Para utilizar `premium_mode` consulta con el encargado de proporcionar las `API_KEY` debido a que su uso implica un costo adicional.[link text](https://)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPwxgQahAw5r"
   },
   "source": [
    "#  1. Instalación de dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-parse\n",
    "pip install PyPDF2\n",
    "pip install Pillow  # Para manejo de imágenes (TIFF) con PIL\n",
    "apt-get update\n",
    "apt-get install -y libreoffice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1739914009329,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "dWfnw5ox6eMy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APNKZb7c6idc"
   },
   "source": [
    "# 2. Librería de Funciones para Conversión a PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1739914030966,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "B1kz9Oim6Xzr"
   },
   "outputs": [],
   "source": [
    "def convert_file_to_pdf(path_original_file):\n",
    "    \"\"\"\n",
    "    Convierte un archivo a PDF, manejando:\n",
    "      - PDF: Retorna la misma ruta.\n",
    "      - TIFF/TIF: Convierte usando PIL (multi-página).\n",
    "      - ZIP: Descomprime, convierte cada archivo interno a PDF y unifica en uno solo.\n",
    "      - Otros formatos (DOC, DOCX, etc.): Convierte usando LibreOffice.\n",
    "    \"\"\"\n",
    "    # 1) Si ya es PDF, retornar la misma ruta\n",
    "    if path_original_file.lower().endswith('.pdf'):\n",
    "        print(f\"El archivo '{path_original_file}' ya está en PDF.\")\n",
    "        return path_original_file\n",
    "\n",
    "    # 2) Detectar extensión\n",
    "    extension = os.path.splitext(path_original_file)[1].lower()\n",
    "\n",
    "    # 2A) ZIP -> Descomprimir + convertir + unificar\n",
    "    if extension == '.zip':\n",
    "        return extract_and_unify_zip_to_pdf(path_original_file)\n",
    "\n",
    "    # 2B) TIFF -> PIL multi-página\n",
    "    if extension in ('.tif', '.tiff'):\n",
    "        return convert_tiff_multi_page_to_pdf(path_original_file)\n",
    "\n",
    "    # 2C) Otros formatos -> LibreOffice\n",
    "    return convert_with_libreoffice(path_original_file)\n",
    "\n",
    "\n",
    "def extract_and_unify_zip_to_pdf(zip_path):\n",
    "    \"\"\"\n",
    "    Descomprime un .zip en una carpeta temporal, convierte cada archivo interno a PDF\n",
    "    y unifica todos los PDFs resultantes en uno solo (orden alfabético).\n",
    "    \"\"\"\n",
    "    # 1) Crear carpeta de extracción\n",
    "    extract_dir = os.path.splitext(zip_path)[0]\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Descomprimir\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            zf.extractall(extract_dir)\n",
    "        print(f\"Archivo ZIP extraído en: {extract_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Al descomprimir '{zip_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "    # 3) (Opcional) Eliminar el ZIP original\n",
    "    try:\n",
    "        os.remove(zip_path)\n",
    "        print(f\"Archivo ZIP original eliminado: {zip_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Advertencia] No se pudo eliminar el archivo ZIP original: {e}\")\n",
    "\n",
    "    # 4) Convertir cada archivo extraído a PDF\n",
    "    pdf_paths = []\n",
    "    for root, dirs, files in os.walk(extract_dir):\n",
    "        for filename in files:\n",
    "            extracted_path = os.path.join(root, filename)\n",
    "            result_pdf = convert_file_to_pdf(extracted_path)\n",
    "            if result_pdf:\n",
    "                if isinstance(result_pdf, str):\n",
    "                    pdf_paths.append(result_pdf)\n",
    "                elif isinstance(result_pdf, list):\n",
    "                    pdf_paths.extend(result_pdf)\n",
    "\n",
    "    if not pdf_paths:\n",
    "        print(f\"[Aviso] No se encontraron archivos convertibles en '{zip_path}'.\")\n",
    "        return None\n",
    "\n",
    "    # 5) Unificar todos los PDFs en uno solo\n",
    "    merged_pdf_path = os.path.join(extract_dir, \"merged_result.pdf\")\n",
    "    if not merge_pdfs(pdf_paths, merged_pdf_path):\n",
    "        return None\n",
    "\n",
    "    print(f\"PDF unificado creado: {merged_pdf_path}\")\n",
    "\n",
    "    # 6) (Opcional) Eliminar los PDFs individuales\n",
    "    for pdf_file in pdf_paths:\n",
    "        if os.path.exists(pdf_file):\n",
    "            os.remove(pdf_file)\n",
    "\n",
    "    return merged_pdf_path\n",
    "\n",
    "\n",
    "def merge_pdfs(pdf_paths, output_path):\n",
    "    \"\"\"\n",
    "    Une una lista de rutas de PDF en un solo archivo.\n",
    "    Retorna True si es exitoso, False si ocurre un error.\n",
    "    \"\"\"\n",
    "    pdf_paths_sorted = sorted(pdf_paths)\n",
    "    writer = PdfWriter()\n",
    "    try:\n",
    "        for pdf_file in pdf_paths_sorted:\n",
    "            reader = PdfReader(pdf_file)\n",
    "            for page in reader.pages:\n",
    "                writer.add_page(page)\n",
    "\n",
    "        with open(output_path, \"wb\") as out_f:\n",
    "            writer.write(out_f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Al unificar PDFs: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def convert_tiff_multi_page_to_pdf(path_tiff_file):\n",
    "    \"\"\"\n",
    "    Convierte un archivo TIFF/TIF (posiblemente multi-página) a un solo PDF.\n",
    "    \"\"\"\n",
    "    directory = os.path.dirname(path_tiff_file)\n",
    "    base_name = os.path.splitext(os.path.basename(path_tiff_file))[0]\n",
    "    pdf_name = base_name + \".pdf\"\n",
    "    pdf_path = os.path.join(directory, pdf_name)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    images = []\n",
    "    try:\n",
    "        with Image.open(path_tiff_file) as img:\n",
    "            while True:\n",
    "                frame = img.copy()\n",
    "                if frame.mode in (\"RGBA\", \"P\"):\n",
    "                    frame = frame.convert(\"RGB\")\n",
    "                images.append(frame)\n",
    "                try:\n",
    "                    img.seek(img.tell() + 1)\n",
    "                except EOFError:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Al abrir {path_tiff_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not images:\n",
    "        print(f\"[Aviso] No se pudieron extraer páginas de {path_tiff_file}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        images[0].save(\n",
    "            pdf_path,\n",
    "            \"PDF\",\n",
    "            resolution=100.0,\n",
    "            save_all=True,\n",
    "            append_images=images[1:]\n",
    "        )\n",
    "        print(f\"PDF multi-página creado: {pdf_path}\")\n",
    "        os.remove(path_tiff_file)  # Eliminar original\n",
    "        return pdf_path\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Al crear el PDF a partir de TIFF: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_with_libreoffice(path_original_file):\n",
    "    \"\"\"\n",
    "    Convierte archivos de texto (DOC, DOCX, ODT, etc.) a PDF usando LibreOffice.\n",
    "    Ajustar la ruta del comando 'soffice' según tu sistema operativo.\n",
    "    \"\"\"\n",
    "    directory = os.path.dirname(path_original_file)\n",
    "    base_name = os.path.splitext(os.path.basename(path_original_file))[0]\n",
    "    pdf_path = os.path.join(directory, base_name + \".pdf\")\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Ajusta la ruta de soffice si usas Linux u otra plataforma.\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"/Applications/LibreOffice.app/Contents/MacOS/soffice\",\n",
    "                \"--headless\",\n",
    "                \"--convert-to\", \"pdf\",\n",
    "                path_original_file,\n",
    "                \"--outdir\", directory\n",
    "            ],\n",
    "            check=True\n",
    "        )\n",
    "        print(f\"PDF creado a partir de '{path_original_file}': {pdf_path}\")\n",
    "        os.remove(path_original_file)  # Eliminar original\n",
    "        return pdf_path\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Al convertir '{path_original_file}' a PDF: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbsKqeIr95XC"
   },
   "source": [
    "# 3. Configuración Previa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1739914068329,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "MJGUHLJb6xt1"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Ajusta tu clave de LlamaParse aquí:\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-L3a9zd-DxP"
   },
   "source": [
    "# 4. Definir la ruta del documento PDF\n",
    "\n",
    "Puedes encontrar algunos archivos de ejemplo en el siguiente [link](https://drive.google.com/drive/folders/1KKJqJ_Z-H2JP_NpA3zHFPU7839--QzF6?usp=sharing). Luego, este archivo debe ser cargado en /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1739914670787,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "pf7H5cpc60P0",
    "outputId": "0758c2ab-51aa-4f4a-a12f-f6d55ddbc1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF multi-página creado: /content/29701.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/29701.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_path = \"/content/29701.tif\"\n",
    "convert_file_to_pdf(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1739914697139,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "vXOrN_vS_uG6",
    "outputId": "35a6ab08-b888-4cda-baa8-3b76bac80e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usaremos el archivo PDF en: /content/29701.pdf\n"
     ]
    }
   ],
   "source": [
    "path_pdf_document = \"/content/29701.pdf\"\n",
    "print(f\"Usaremos el archivo PDF en: {path_pdf_document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDpnU8xB-0wf"
   },
   "source": [
    "# 5. Definición de las Instrucciones de Parseo\n",
    "\n",
    "Consiste en explicar, en términos generales la estructura del documento que se proporcionará y lo que se espera que haga el parser (por ejemplo, recuperar integramente el contenido y en idioa español)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1739914715306,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "L_7Jyw-w629x",
    "outputId": "b533ce9d-2553-4f5c-ef93-1917dfe358b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrucciones de parseo definidas.\n"
     ]
    }
   ],
   "source": [
    "parsing_instructions = '''\n",
    "The document contains structured text that includes headers, dates, names of individuals, institutions, and places, as well as numbered sections, lists, and tables. Many of these documents feature text that is highly deteriorated and requires careful interpretation, contextualization, and reconstruction. Non-essential elements, such as scratches, signatures, and diagonal annotations, must be omitted.\n",
    "To ensure the integrity of the extracted information, the text must be preserved in its literal form without summarizing, paraphrasing, or modifying its meaning. Treat each document as evidentiary material, prioritizing rigorous and faithful extraction practices.\n",
    "Recognize that most documents are typewritten, which introduces specific challenges such as ink smudges, duplicated letters, and words split across lines. Proactively correct these errors, ensuring clarity and precision in the recovered content.\n",
    "While processing, handle page breaks to maintain the narrative flow, and retain the original structure of tables and lists without flattening their format. Extract and clearly highlight key names, dates, and places. Quotes, dialogues, abbreviations, and codes must be preserved exactly as they appear. Non-textual elements should be omitted to focus solely on the written content.\n",
    "The output should adhere to Markdown formatting conventions but must not include code block tags such as markdown. Use bold formatting for headers, numbered or bulleted lists for structured sections, block quotes for quoted material, and Markdown-compatible tables for tabular data. Narrative text should be continuous, providing both factual information and detailed descriptions, while preserving the integrity and original context of the document. Additionally, prioritize correcting OCR-related errors caused by typewriter artifacts whenever possible.\n",
    "The response must be exclusively in the original language of the document, which is generally Spanish. No translation or language modification is allowed.\n",
    "'''\n",
    "\n",
    "print(\"Instrucciones de parseo definidas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6RKkVPo_KVq"
   },
   "source": [
    "# 6. Carga y Procesamiento del Documento con LlamaParse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51360,
     "status": "ok",
     "timestamp": 1739914777471,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "imGTpyta645_",
    "outputId": "4ec84269-567f-43d3-e4ab-1403d068596d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 42e95bfe-0aff-4223-88dd-17d3eaaa1189\n",
      ".Documento parseado correctamente.\n",
      "Total de secciones extraídas: 13\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el documento usando LlamaParse con las instrucciones definidas\n",
    "document = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    premium_mode=False,\n",
    "    parsing_instructions=parsing_instructions,\n",
    "    language='es',\n",
    "    skip_diagonal_text=True,\n",
    "    do_not_unroll_columns=False\n",
    ").load_data(path_pdf_document)\n",
    "\n",
    "print(\"Documento parseado correctamente.\")\n",
    "print(f\"Total de secciones extraídas: {len(document)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a4CJUfgAQhB"
   },
   "source": [
    "# 7. Guardar el Texto Recuperado en un Archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1739914821576,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "Fz0YzlaR66o8",
    "outputId": "1ffc5f52-49f0-44c1-a1ea-0ab4e63a6940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo parseado ha sido guardado en: /content/outputs/02.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_text = ''\n",
    "for i in range(len(document)):\n",
    "    full_text += '\\n\\n'\n",
    "    full_text += document[i].text\n",
    "\n",
    "# Crear carpeta y archivo de salida\n",
    "directory = \"/content/outputs\"\n",
    "file_name = \"02.txt\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Escribir el contenido parseado en un .txt\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(full_text)\n",
    "\n",
    "print(f\"El archivo parseado ha sido guardado en: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "753RmM4HAcj0"
   },
   "source": [
    "# 8. Visualización de una Página o Sección\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1739914891474,
     "user": {
      "displayName": "Camilo Gutierrez",
      "userId": "18212724788807677958"
     },
     "user_tz": 180
    },
    "id": "Sm8kXa7_69WW",
    "outputId": "fc696afc-6424-4a47-86e4-7a481c92ffca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ministerio de Energia\n",
      "\n",
      "# SSC\n",
      "\n",
      "# SuPENNTENDEA(U DeelecircIDAD\n",
      "\n",
      "# Gobierno de Chile\n",
      "\n",
      "Regularizar y solucionar problemas formales de las CUOs que fueran necesarios para permitir el desarrollo de los proyectos amparados en ellas.\n",
      "\n",
      "Teniendo en cuenta la preocupación que ha puesto el Estado en el tema descrito; Chungungo tomó la decisión de desarrollar el Proyecto en un terreno de propiedad fiscal sobre el cual el MBN otorgó una CUO que originalmente fue otorgada a la empresa Hydrochile SA. (en adelante \"Hydrochile\") por medio de la Resolución Exenta N° 758 del julio de 2015, del MBN, CUO que actualmente es de propiedad de Chungungo.\n",
      "\n",
      "En forma previa y luego paralela a las gestiones de obtención del ICC y la RCA del Proyecto; a mediados del año 2017 Chungungo inició negociaciones con Hydrochile para adquirir la CUO, previo a lo cual debían solucionarse problemas formales con el MBN, ya que luego de la obtención de la CUO Hydrochile dejó pendiente la firma del respectivo contrato de concesión con el Fisco y, por tanto; también su inscripción en el Conservador de Bienes Raíces.\n",
      "\n",
      "En lo que respecta a la CUO del Proyecto; el Titulo VIII de la OMI daba cuenta que bastaba para solucionar su problema formal el que su titular hiciera una presentación ante el MBN solicitando acoger la CUO a las condiciones de dicha orden ministerial y pagar un \"Costo de Ingreso\" de hasta 1.000 UF. Se trata por tanto de un derecho que asiste al titular de una CUO para regularizarla; sin que su aceptación dependa del criterio del MBN. Así, en caso de la CUO del Proyecto se trataba únicamente de cumplir con la presentación aludida; realizar el pago de hasta las 1.000 UF y esperar su formalización por parte del Ministerio.\n",
      "\n",
      "Asimismo y con respecto al tiempo de tramitación; los primeros cuatro casos de CUOs que solicitaron acogerse a las condiciones de la OMI fueron resueltos en solo cuatro meses contados desde la presentación de la solicitud respectiva. Por ejemplo; en el caso de Austrian Solar Chile Cuatro; cuya solicitud fue presentada el 11 de mayo de 2017 y resuelta el 20 de septiembre del mismo año (Res Ex. 299/2017). Asimismo; está el caso de Viento Fuerte SA, cuya solicitud fue presentada con fecha 9 de agosto y resuelta el 13 de diciembre del mismo año (Res Ex 392/2017).\n",
      "\n",
      "Conforme a lo anterior y como condición previa a la adquisición de la CUO, se acordó con Hydrochile que ésta solicitaría ante el MBN la autorización para acoger su CUO a las condiciones de la OMI, con el objeto de obtener un nuevo plazo para firmar el contrato de concesión de uso oneroso con el Fisco y asimismo contar con un periodo de construcción suficiente para el desarrollo del Proyecto.\n",
      "\n",
      "En razón de lo anterior y de acuerdo al contrato de transferencia suscrito con Chungungo; Hydrochile solicitó al MBN acoger la CUO a las condiciones de la OMI mediante carta de fecha 13 de septiembre de 2017 (en adelante la \"Solicitud OM\"). Esto es, hace ya 18 meses.\n",
      "\n",
      "Con fecha 22 de junio de 2018, a pesar de que el MBN no había resuelto la Solicitud OM habiendo transcurrido nueve meses desde su presentación; pero tomando en cuenta que su aceptación no tenía más riesgo que su demora; Hydrochile cedió; vendió y transfirió a Chungungo la CUO por medio de escritura pública de esa fecha; otorgada en la notaría de don Juan Ricardo San Martín. Esta transferencia fue comunicada al MBN con fecha 29 de junio de 2018.\n",
      "\n",
      "Dirección: Av. Libertador Bernardo O'Higgins N° 1465, torre 3, local 10, Santiago Chile\n",
      "\n",
      "Atención Ciudadana: 6006000732 Desde Celulares: 2 2712 7000\n",
      "\n",
      "WwW-sec.ci\n"
     ]
    }
   ],
   "source": [
    "# Puedes cambiar el índice para ver otras partes del documento\n",
    "\n",
    "pagina_a_visualizar = 3\n",
    "\n",
    "if pagina_a_visualizar < len(document):\n",
    "    print(document[pagina_a_visualizar].text)\n",
    "else:\n",
    "    print(f\"Índice fuera de rango. El documento sólo tiene {len(document)} partes extraídas.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb",
     "timestamp": 1726083614122
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
