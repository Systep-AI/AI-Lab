{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OCR**\n",
        "\n",
        "En este notebook veremos cómo **parsear documentos** con [LlamaParse](https://pypi.org/project/llama-parse/) para extraer texto de forma estructurada y confiable.  \n",
        "\n",
        "El flujo principal será:\n",
        "\n",
        "1. **Instalación de dependencias.**  \n",
        "2. **Importación de librerías.**  \n",
        "3. **Configuración previa (variables de entorno).**  \n",
        "4. **Definir la ruta del documento PDF final.**  \n",
        "5. **Establecer instrucciones de parseo (OCR y formato).**  \n",
        "6. **Procesar el PDF con LlamaParse.**  \n",
        "7. **Almacenar el texto resultante en un archivo local.**  \n",
        "8. **Visualizar una sección del documento parseado.**  \n",
        "\n",
        "\n",
        "\n",
        "## **Notas**\n",
        "- **LlamaParse** solo procesa documentos pdf. Si necesitas extraer texto de un archivo que NO sea PDF, consulta con el desarrollador para acceder a la **librería de conversión** para transformarlo en un PDF válido.\n",
        "- Configura la variable de entorno `LLAMA_CLOUD_API_KEY` con tu clave real para poder usar **LlamaParse**.\n",
        "- Ajusta los parámetros de `LlamaParse` (por ejemplo, `premium_mode`, `language`, etc.) en función de tus necesidades de OCR y parseo.\n",
        "- Para utilizar `premium_mode` consulta con el encargado de proporcionar las `API_KEY` debido a que su uso implica un costo adicional.\n",
        "\n"
      ],
      "metadata": {
        "id": "QkC6T4zE6GHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1. Instalación de dependencias\n"
      ],
      "metadata": {
        "id": "QPwxgQahAw5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-parse"
      ],
      "metadata": {
        "id": "Bi5Q5tusyB4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b524141-43ed-47ec-b30b-cbd9e3d00fd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-parse\n",
            "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.1 (from llama-parse)\n",
            "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama-parse) (8.1.8)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.11 (from llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n",
            "Collecting llama-index-core>=0.11.0 (from llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading llama_index_core-0.12.19-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pydantic!=2.10 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama-parse) (2.10.6)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (2025.1.31)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (0.28.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.11.12)\n",
            "Collecting dataclasses-json (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.17.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.1->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.1->llama-parse) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (0.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (1.3.1)\n",
            "Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
            "Downloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
            "Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.12.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, dirtyjson, python-dotenv, mypy-extensions, marshmallow, typing-inspect, tiktoken, llama-cloud, dataclasses-json, llama-index-core, llama-cloud-services, llama-parse\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.12 llama-cloud-services-0.6.1 llama-index-core-0.12.19 llama-parse-0.6.1 marshmallow-3.26.1 mypy-extensions-1.0.0 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Importar librerías"
      ],
      "metadata": {
        "id": "uXlDEVN65lI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nest_asyncio\n",
        "from llama_parse import LlamaParse"
      ],
      "metadata": {
        "id": "dWfnw5ox6eMy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Configuración Previa\n"
      ],
      "metadata": {
        "id": "IbsKqeIr95XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajusta tu clave de LlamaParse aquí: (CONSULTA CON EL DESARROLLADOR PARA OBTENER LA API-KEY)\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-\""
      ],
      "metadata": {
        "id": "MJGUHLJb6xt1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Definir la ruta del documento PDF\n",
        "\n",
        "Puedes encontrar algunos archivos de ejemplo en el la carpeta del repositorio"
      ],
      "metadata": {
        "id": "P-L3a9zd-DxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_pdf_document = \"/content/11050.pdf\"\n",
        "\n",
        "print(f\"Usaremos el archivo PDF en: {path_pdf_document}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXOrN_vS_uG6",
        "outputId": "35af8efc-cfa1-4ac0-97bd-f415e455625f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usaremos el archivo PDF en: /content/11050.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Definición de las Instrucciones de Parseo\n",
        "\n",
        "Consiste en explicar, en términos generales la estructura del documento que se proporcionará y lo que se espera que haga el parser (por ejemplo, recuperar integramente el contenido y en idioa español)\n"
      ],
      "metadata": {
        "id": "uDpnU8xB-0wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsing_instructions = '''\n",
        "The document contains structured text that includes headers, dates, names of individuals, institutions, and places, as well as numbered sections, lists, and tables. Many of these documents feature text that is highly deteriorated and requires careful interpretation, contextualization, and reconstruction. Non-essential elements, such as scratches, signatures, and diagonal annotations, must be omitted.\n",
        "To ensure the integrity of the extracted information, the text must be preserved in its literal form without summarizing, paraphrasing, or modifying its meaning. Treat each document as evidentiary material, prioritizing rigorous and faithful extraction practices.\n",
        "Recognize that most documents are typewritten, which introduces specific challenges such as ink smudges, duplicated letters, and words split across lines. Proactively correct these errors, ensuring clarity and precision in the recovered content.\n",
        "While processing, handle page breaks to maintain the narrative flow, and retain the original structure of tables and lists without flattening their format. Extract and clearly highlight key names, dates, and places. Quotes, dialogues, abbreviations, and codes must be preserved exactly as they appear. Non-textual elements should be omitted to focus solely on the written content.\n",
        "The output should adhere to Markdown formatting conventions but must not include code block tags such as markdown. Use bold formatting for headers, numbered or bulleted lists for structured sections, block quotes for quoted material, and Markdown-compatible tables for tabular data. Narrative text should be continuous, providing both factual information and detailed descriptions, while preserving the integrity and original context of the document. Additionally, prioritize correcting OCR-related errors caused by typewriter artifacts whenever possible.\n",
        "The response must be exclusively in the original language of the document, which is generally Spanish. No translation or language modification is allowed.\n",
        "'''\n",
        "\n",
        "print(\"Instrucciones de parseo definidas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_7Jyw-w629x",
        "outputId": "06b1c15f-875b-48b1-829e-e9b765418160"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instrucciones de parseo definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Carga y Procesamiento del Documento con LlamaParse\n",
        "\n",
        "Para un mayor detalle de la configuración, visita las [opciones del parser](https://https://docs.cloud.llamaindex.ai/llamaparse/features/parsing_options)"
      ],
      "metadata": {
        "id": "Z6RKkVPo_KVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Permite que asyncio funcione sin problemas en entornos con un loop de eventos en ejecución (como Jupyter o Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Carga y procesa el documento PDF usando LlamaParse con las configuraciones especificadas\n",
        "document = LlamaParse(\n",
        "    result_type=\"markdown\",        # Define que el resultado será en formato Markdown\n",
        "    premium_mode=False,            # No usa el modo premium (costo extra)\n",
        "    parsing_instructions=parsing_instructions,  # Instrucciones personalizadas para el parsing\n",
        "    language='es',                 # Define el idioma español para la extracción de texto. Un listado extenso de lenguajes admitidos está disponible en https://github.com/run-llama/llama_cloud_services/blob/main/llama_cloud_services/parse/utils.py#L16\n",
        "    skip_diagonal_text=True,        # Omite texto en diagonal para mejorar la limpieza del documento\n",
        "    do_not_unroll_columns=False     # LlamaParse intentará desenrollar las columnas (colocándolas una después de la otra en el orden de lectura). Si se establece do_not_unroll_columns = True, LlamaParse no podrá hacerlo.\n",
        ").load_data(path_pdf_document)      # Carga y extrae los datos del archivo PDF especificado\n",
        "\n",
        "\n",
        "print(\"\\n Documento parseado correctamente. \\n\")\n",
        "print(f\"Total de secciones extraídas: {len(document)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imGTpyta645_",
        "outputId": "b62e3a68-5682-4a1c-ec3d-6d9c71f97f50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 1903454b-ee51-455e-b127-53d2abf9081a\n",
            ".Documento parseado correctamente.\n",
            "Total de secciones extraídas: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Guardar el Texto Recuperado en un Archivo\n"
      ],
      "metadata": {
        "id": "6a4CJUfgAQhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = ''\n",
        "for i in range(len(document)):\n",
        "    full_text += '\\n\\n'\n",
        "    full_text += document[i].text\n",
        "\n",
        "# Crear archivo de salida\n",
        "path_txt_document = os.path.splitext(path_pdf_document)[0] + \".txt\"\n",
        "\n",
        "# Escribir el contenido parseado en un .txt\n",
        "with open(path_txt_document, \"w\") as file:\n",
        "    file.write(full_text)\n",
        "\n",
        "print(f\"El archivo parseado ha sido guardado en: {path_txt_document}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0YzlaR66o8",
        "outputId": "fb8ab8d0-3e89-4103-d846-960004e31ede"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo parseado ha sido guardado en: /content/11050.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Visualización de una Página o Sección\n"
      ],
      "metadata": {
        "id": "753RmM4HAcj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Puedes cambiar el índice en pagina_a_visualizar para ver otras partes del documento\n",
        "\n",
        "pagina_a_visualizar = 3\n",
        "\n",
        "if pagina_a_visualizar < len(document):\n",
        "    print(document[pagina_a_visualizar].text)\n",
        "else:\n",
        "    print(f\"Índice fuera de rango. El documento sólo tiene {len(document)} partes extraídas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm8kXa7_69WW",
        "outputId": "b189fe3e-feee-43af-8a97-d00bbb299fcb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# RESOLUCION EXENTA ELECTRONICA N° 11050\n",
            "\n",
            "Santiago, 01 de Marzo de 2022\n",
            "\n",
            "personas y, por tanto, la ejecución de tales estudios en los tiempos que habitualmente se requieren para estos efectos.\n",
            "\n",
            "En respuesta a la solicitud indicada en el párrafo anterior, el SEA, mediante Resolución Exenta N°197 de fecha 28 de septiembre de 2020 otorgó a Grenergy la extensión del plazo solicitado hasta el 30 de noviembre de 2020, esto es, por un término de 2 meses adicionales al de la suspensión por dicha autoridad ya decretada, reconociendo con ello, los argumentos referidos a la fuerza mayor que produjeron las medidas, restricciones sanitarias y de movilidad tomadas por la autoridad durante la pandemia.\n",
            "\n",
            "Luego, mediante carta de fecha 27 de noviembre de 2020, Grenergy solicitó al SEA que se mantuviera la suspensión del plazo de evaluación del procedimiento ambiental del Proyecto hasta el 15 de enero de 2021.\n",
            "\n",
            "Cabe señalar que, en dicho momento, continuaban las restricciones ya señaladas.\n",
            "\n",
            "En respuesta a la solicitud indicada en el párrafo anterior, el SEA, mediante resolución exenta N° 258 de fecha 30 de noviembre de 2020 otorgó a Grenergy la extensión del plazo solicitado hasta el 30 de diciembre de 2020.\n",
            "\n",
            "De acuerdo con lo anteriormente indicado, el Proyecto obtuvo una prórroga por 1 mes adicional al plazo ya otorgado. Posteriormente, con fecha 29 de diciembre de 2020, Grenergy presentó la adenda en respuesta del ICSARA N° 210/2020.\n",
            "\n",
            "Luego, el 29 de enero de 2021 el SEA dictó el ICSARA Complementario N° 32/2021, respecto del cual Grenergy debía presentar la correspondiente adenda complementaria con fecha 26 de febrero de 2021.\n",
            "\n",
            "No obstante lo anterior, mediante carta de fecha 23 de febrero de 2021, Grenergy solicitó al SEA que se mantuviera la suspensión del plazo de evaluación del procedimiento ambiental del Proyecto hasta el 9 de abril de 2021, con el objeto de responder adecuada y satisfactoriamente a las observaciones, rectificaciones y ampliaciones a la DIA, contenidas en el documento ICSARA Complementario N° 32/2021.\n",
            "\n",
            "En respuesta a la solicitud indicada en el párrafo anterior, el SEA, mediante Resolución Exenta N° 54 de fecha 23 de febrero de 2021, otorgó a Grenergy la extensión del plazo solicitado hasta el 9 de abril de 2021.\n",
            "\n",
            "De acuerdo con lo anteriormente indicado, el Proyecto obtuvo una prórroga por 1 mes y 15 días adicionales a la suspensión del plazo ya otorgada. Después, con fecha 9 de abril de 2021, Grenergy presentó la adenda complementaria en respuesta del ICSARA Complementaria N° 32/2021.\n",
            "\n",
            "Las razones que tuvo Grenergy para solicitar que se extendiera la suspensión fue la de responder adecuada y satisfactoriamente las observaciones, rectificaciones y ampliaciones a la DIA, contenidas en el documento ICSARA N° 210/2020, debido principalmente a la necesidad de ejecutar nuevos estudios que requerían necesariamente de trabajo en terreno, con el fin de dar respuestas fundadas que permitieran justificar la inexistencia de los efectos, características y circunstancias listados en el Artículo 11 de la Ley 19.300. En específico, se requirió mayor tiempo debido a la necesidad de procesar la información para dar respuesta a las observaciones realizadas por la Autoridad.\n",
            "\n",
            "Es importante mencionar que, la imposibilidad de realizar los estudios con mayor rapidez respondió principalmente a que en dicho momento el país se encontraba en pleno proceso de pandemia, producto del brote mundial del COVID-19, y bajo un Estado de Excepción Constitucional de Catástrofe en todo el territorio nacional, que impidió o ralentizó la movilidad de personas y por tanto ejecución de terrenos en gran parte del territorio nacional.\n",
            "\n",
            "Caso:1638434 Acción:3010697 Documento:3028738\n",
            "\n",
            "V°B° AOP/JSF/JCC/JCS/SL.\n",
            "\n",
            "https://wlhttp.sec.cl/timesM/global/imgPDF.jsp?pa=3010697&pd=3028738&pc=1638434\n",
            "\n",
            "Dirección: Avenida Bernardo O’Higgins 1465 – Santiago Downtown, Santiago Chile - www.sec.cl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}